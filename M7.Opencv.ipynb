{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV is a Python library that allows you to perform image processing and computer vision tasks. It provides a wide range of features, including object detection, face recognition, and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "img = cv.imread(\"C:/Users/User7/Desktop/g.jpg\")\n",
    "\n",
    "cv.imshow(\"Display window\", img)\n",
    "k = cv.waitKey(0) # Wait for a keystroke in the window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KERAS FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 27s 78ms/step - loss: 0.4712 - accuracy: 0.8501 - val_loss: 0.0931 - val_accuracy: 0.9718\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 22s 73ms/step - loss: 0.1574 - accuracy: 0.9531 - val_loss: 0.0534 - val_accuracy: 0.9820\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 0.1201 - accuracy: 0.9635 - val_loss: 0.0419 - val_accuracy: 0.9856\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 22s 73ms/step - loss: 0.1013 - accuracy: 0.9692 - val_loss: 0.0385 - val_accuracy: 0.9867\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 22s 75ms/step - loss: 0.0877 - accuracy: 0.9738 - val_loss: 0.0323 - val_accuracy: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User7\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#  PRELABELED DATASET\n",
    "# import the keras pakage\n",
    "from  keras.datasets import mnist \n",
    "\n",
    "#  NUMEROUS IMPLEMENTED LAYERS AND PARAMETERS\n",
    "# import th eanother pakages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras import utils\n",
    "import numpy as np\n",
    "import np_utils\n",
    "\n",
    "\n",
    "# MULTIPLE METHODS FRO DATA PREPROCESSING\n",
    "\n",
    "# divide the  Data into (X_train ,Y_train,X_test,Y_test)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "#reshape in form of (60000, 28, 28, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')\n",
    "#normalize to get data in range of 0-1\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "number_of_classes = 10\n",
    "y_train = utils.to_categorical(y_train, number_of_classes)\n",
    "y_test = utils.to_categorical(y_test, number_of_classes)\n",
    "\n",
    "\n",
    "''' add() Method in Keras\n",
    "To add layers imported above by specifying parameters to build\n",
    "your digit classifier, it is done using .add() method.'''\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "'''compile() Method in Keras\n",
    "Before training, you need to configure your \n",
    "learning process which is done using .compile() method.'''\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=200) \n",
    "model.save(\"model.h5\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 278ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "'''compile() Method in Keras\n",
    "Before training, you need to configure your learning process which is done using .compile() method\n",
    ".'''\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread(\"C:/Users/User7/Desktop/gourav.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "# resize image\n",
    "resized = cv2.resize(img, (28,28), interpolation = cv2.INTER_AREA)\n",
    "img = np.resize(resized, (28,28,1))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)\n",
    "y_pred = model.predict(im2arr)\n",
    "predicted_digit=np.argmax(y_pred)\n",
    "print(y_pred)\n",
    "print(predicted_digit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Example categorical labels\n",
    "labels = ['cat', 'dog', 'bird', 'dog', 'cat']\n",
    "\n",
    "# Create a mapping of unique labels to numerical integers\n",
    "label_to_int = {label: i for i, label in enumerate(set(labels))}\n",
    "\n",
    "# Convert the string labels to numerical integer labels\n",
    "numerical_labels = [label_to_int[label] for label in labels]\n",
    "\n",
    "# Perform one-hot encoding on the numerical labels\n",
    "encoded_labels = to_categorical(numerical_labels)\n",
    "\n",
    "print(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REINFORCMENT LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m q_table\n\u001b[0;32m     37\u001b[0m \u001b[39m# Train Q-learning agent\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m q_table \u001b[39m=\u001b[39m q_learning(env)\n\u001b[0;32m     40\u001b[0m \u001b[39m# Test the agent\u001b[39;00m\n\u001b[0;32m     41\u001b[0m state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36mq_learning\u001b[1;34m(env, episodes, alpha, gamma, epsilon)\u001b[0m\n\u001b[0;32m     21\u001b[0m     action \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39msample()\n\u001b[0;32m     22\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(q_table[state, :])\n\u001b[0;32m     24\u001b[0m     \u001b[39m# Assuming state_space_size and action_space_size are appropriate values for your environment\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[39m# q_table = np.zeros((state, action))\u001b[39;00m\n\u001b[0;32m     28\u001b[0m next_state, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create the CartPole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Q-learning algorithm\n",
    "def q_learning(env, episodes=1000, alpha=0.1, gamma=0.99, epsilon=0.1):\n",
    "    n_actions = env.action_space.n\n",
    "    n_states = env.observation_space.shape[0]\n",
    "    q_table = np.zeros((n_states, n_actions))\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state, :])\n",
    "                # Assuming state_space_size and action_space_size are appropriate values for your environment\n",
    "                # q_table = np.zeros((state, action))\n",
    "\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            q_next = np.max(q_table[next_state, :])\n",
    "            q_table[state, action] = (1 - alpha) * q_table[state, action] + alpha * (reward + gamma * q_next)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "    return q_table\n",
    "\n",
    "# Train Q-learning agent\n",
    "q_table = q_learning(env)\n",
    "\n",
    "# Test the agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = np.argmax(q_table[state, :])\n",
    "    next_state, _, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    state = next_state\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforcment learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "99/99 [==============================] - 1s 1ms/step - loss: 0.4280\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.2304\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0788\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0241\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 0.0192\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 0s 991us/step - loss: 0.0195\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0189\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 0s 996us/step - loss: 0.0191\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 0s 974us/step - loss: 0.0193\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 0s 997us/step - loss: 0.0191\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0193\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 0s 976us/step - loss: 0.0193\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 0s 989us/step - loss: 0.0195\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 0s 983us/step - loss: 0.0192\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 0s 985us/step - loss: 0.0195\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 0s 979us/step - loss: 0.0190\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 0s 998us/step - loss: 0.0191\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 0s 985us/step - loss: 0.0194\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 0s 998us/step - loss: 0.0191\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 0s 989us/step - loss: 0.0194\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 0s 971us/step - loss: 0.0191\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 0s 981us/step - loss: 0.0191\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 0s 989us/step - loss: 0.0194\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 0s 993us/step - loss: 0.0195\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 0s 981us/step - loss: 0.0191\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 0s 991us/step - loss: 0.0188\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 0s 981us/step - loss: 0.0191\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 0s 991us/step - loss: 0.0189\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 0s 991us/step - loss: 0.0191\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 0s 999us/step - loss: 0.0197\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0191\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 0s 984us/step - loss: 0.0192\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 0s 970us/step - loss: 0.0190\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 0s 992us/step - loss: 0.0193\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0194\n",
      "Epoch 68/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0195\n",
      "Epoch 69/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 70/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 71/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0193\n",
      "Epoch 72/100\n",
      "99/99 [==============================] - 0s 989us/step - loss: 0.0191\n",
      "Epoch 73/100\n",
      "99/99 [==============================] - 0s 988us/step - loss: 0.0192\n",
      "Epoch 74/100\n",
      "99/99 [==============================] - 0s 997us/step - loss: 0.0192\n",
      "Epoch 75/100\n",
      "99/99 [==============================] - 0s 985us/step - loss: 0.0193\n",
      "Epoch 76/100\n",
      "99/99 [==============================] - 0s 999us/step - loss: 0.0193\n",
      "Epoch 77/100\n",
      "99/99 [==============================] - 0s 964us/step - loss: 0.0191\n",
      "Epoch 78/100\n",
      "99/99 [==============================] - 0s 981us/step - loss: 0.0190\n",
      "Epoch 79/100\n",
      "99/99 [==============================] - 0s 990us/step - loss: 0.0190\n",
      "Epoch 80/100\n",
      "99/99 [==============================] - 0s 972us/step - loss: 0.0187\n",
      "Epoch 81/100\n",
      "99/99 [==============================] - 0s 981us/step - loss: 0.0190\n",
      "Epoch 82/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 83/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0191\n",
      "Epoch 84/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0190\n",
      "Epoch 85/100\n",
      "99/99 [==============================] - 0s 987us/step - loss: 0.0192\n",
      "Epoch 86/100\n",
      "99/99 [==============================] - 0s 975us/step - loss: 0.0196\n",
      "Epoch 87/100\n",
      "99/99 [==============================] - 0s 991us/step - loss: 0.0190\n",
      "Epoch 88/100\n",
      "99/99 [==============================] - 0s 981us/step - loss: 0.0195\n",
      "Epoch 89/100\n",
      "99/99 [==============================] - 0s 981us/step - loss: 0.0190\n",
      "Epoch 90/100\n",
      "99/99 [==============================] - 0s 990us/step - loss: 0.0192\n",
      "Epoch 91/100\n",
      "99/99 [==============================] - 0s 981us/step - loss: 0.0192\n",
      "Epoch 92/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 93/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 94/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0190\n",
      "Epoch 95/100\n",
      "99/99 [==============================] - 0s 998us/step - loss: 0.0194\n",
      "Epoch 96/100\n",
      "99/99 [==============================] - 0s 961us/step - loss: 0.0191\n",
      "Epoch 97/100\n",
      "99/99 [==============================] - 0s 981us/step - loss: 0.0190\n",
      "Epoch 98/100\n",
      "99/99 [==============================] - 0s 969us/step - loss: 0.0197\n",
      "Epoch 99/100\n",
      "99/99 [==============================] - 0s 972us/step - loss: 0.0191\n",
      "Epoch 100/100\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.0190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d1320d3070>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  : Training an image classifier from scratch on the Kaggle Cats vs Dogs dataset.\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate synthetic timeseries data\n",
    "def generate_timeseries_data(n_steps):\n",
    "    time = np.linspace(0, 2*np.pi, n_steps)\n",
    "    data = np.sin(time) + np.random.normal(0, 0.1, n_steps)\n",
    "    return data\n",
    "\n",
    "n_steps = 100\n",
    "data = generate_timeseries_data(n_steps)\n",
    "\n",
    "# Prepare data for LSTM (input and target)\n",
    "X = data[:-1]\n",
    "y = data[1:]\n",
    "\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X = X.reshape(-1, 1, 1)\n",
    "\n",
    "# Create LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
